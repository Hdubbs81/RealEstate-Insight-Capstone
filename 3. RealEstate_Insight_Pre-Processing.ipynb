{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d239ea92",
   "metadata": {},
   "source": [
    "# 3. Pre-Processing <a id=\"data_wrangling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c297a1fe",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "# Table of Contents  \n",
    "3.1. [Introduction](#introduction) <br>\n",
    "3.2. [Imports](#imports)  <br>\n",
    "3.3. [Data Processing](#process)<br>\n",
    "3.4. [Data Splitting](#split)<br>\n",
    "3.5. [Save Updated Data](#save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0152de6",
   "metadata": {},
   "source": [
    "## 3.1 Introduction<a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c3980",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create a cleaned development dataset to be used to complete the modeling step of my project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818c1ac",
   "metadata": {},
   "source": [
    "## 3.2 Imports<a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb61af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65cd6e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Capstone 3/df_eda.csv')\n",
    "print(\"Dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d885beb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceDataset</th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>StateName</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZORI</td>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2367.192976</td>\n",
       "      <td>2015Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZORI</td>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>2382.571737</td>\n",
       "      <td>2015Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZORI</td>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2401.539081</td>\n",
       "      <td>2015Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZORI</td>\n",
       "      <td>394425</td>\n",
       "      <td>50</td>\n",
       "      <td>Buffalo, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>805.691732</td>\n",
       "      <td>2015Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZORI</td>\n",
       "      <td>394425</td>\n",
       "      <td>50</td>\n",
       "      <td>Buffalo, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>819.385346</td>\n",
       "      <td>2015Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>ZORDI</td>\n",
       "      <td>394326</td>\n",
       "      <td>607</td>\n",
       "      <td>Amsterdam, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>2024Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>ZORDI</td>\n",
       "      <td>394504</td>\n",
       "      <td>629</td>\n",
       "      <td>Cortland, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>2024Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>ZORDI</td>\n",
       "      <td>394504</td>\n",
       "      <td>629</td>\n",
       "      <td>Cortland, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2024Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>ZORDI</td>\n",
       "      <td>395084</td>\n",
       "      <td>784</td>\n",
       "      <td>Seneca Falls, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>2024Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>ZORDI</td>\n",
       "      <td>395084</td>\n",
       "      <td>784</td>\n",
       "      <td>Seneca Falls, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2024Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9882 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SourceDataset  RegionID  SizeRank        RegionName StateName       Date  \\\n",
       "0             ZORI    394913         1      New York, NY        NY 2015-01-31   \n",
       "1             ZORI    394913         1      New York, NY        NY 2015-02-28   \n",
       "2             ZORI    394913         1      New York, NY        NY 2015-03-31   \n",
       "3             ZORI    394425        50       Buffalo, NY        NY 2015-01-31   \n",
       "4             ZORI    394425        50       Buffalo, NY        NY 2015-02-28   \n",
       "...            ...       ...       ...               ...       ...        ...   \n",
       "9877         ZORDI    394326       607     Amsterdam, NY        NY 2024-05-31   \n",
       "9878         ZORDI    394504       629      Cortland, NY        NY 2024-04-30   \n",
       "9879         ZORDI    394504       629      Cortland, NY        NY 2024-05-31   \n",
       "9880         ZORDI    395084       784  Seneca Falls, NY        NY 2024-04-30   \n",
       "9881         ZORDI    395084       784  Seneca Falls, NY        NY 2024-05-31   \n",
       "\n",
       "            Value Quarter  \n",
       "0     2367.192976  2015Q1  \n",
       "1     2382.571737  2015Q1  \n",
       "2     2401.539081  2015Q1  \n",
       "3      805.691732  2015Q1  \n",
       "4      819.385346  2015Q1  \n",
       "...           ...     ...  \n",
       "9877   138.000000  2024Q2  \n",
       "9878    34.000000  2024Q2  \n",
       "9879    31.000000  2024Q2  \n",
       "9880    65.000000  2024Q2  \n",
       "9881    77.000000  2024Q2  \n",
       "\n",
       "[9882 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9cb35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract useful features from the Date column\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Quarter'] = df['Date'].dt.quarter\n",
    "\n",
    "# Drop the original Date column\n",
    "df = df.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfeeefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9882 entries, 0 to 9881\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   SourceDataset  9882 non-null   object \n",
      " 1   RegionID       9882 non-null   int64  \n",
      " 2   SizeRank       9882 non-null   int64  \n",
      " 3   RegionName     9882 non-null   object \n",
      " 4   StateName      9882 non-null   object \n",
      " 5   Value          9882 non-null   float64\n",
      " 6   Quarter        9882 non-null   int32  \n",
      " 7   Year           9882 non-null   int32  \n",
      " 8   Month          9882 non-null   int32  \n",
      "dtypes: float64(1), int32(3), int64(2), object(3)\n",
      "memory usage: 579.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f68aca",
   "metadata": {},
   "source": [
    "## 3.3 Data Pre-processing<a id=\"process\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2641de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable column and feature columns\n",
    "target_column = 'Value'\n",
    "feature_columns = df.columns.difference([target_column, 'SourceDataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8299dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = df[feature_columns].select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = df[feature_columns].select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5edd674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18218a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(df, pipeline, target_column):\n",
    "    try:\n",
    "        # Separate features and target\n",
    "        X = df[feature_columns]\n",
    "        y = df[target_column]\n",
    "        \n",
    "        # Preprocess the features\n",
    "        print(\"Preprocessing features...\")\n",
    "        X_preprocessed = pipeline.fit_transform(X)\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = numeric_features.tolist() + pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()\n",
    "        \n",
    "        # Debug: Print the feature names and their count\n",
    "        print(f\"Feature names: {feature_names}\")\n",
    "        print(f\"Number of feature names: {len(feature_names)}\")\n",
    "        \n",
    "        # Check the shape of the transformed features and feature names\n",
    "        print(f\"Shape of transformed features: {X_preprocessed.shape}\")\n",
    "        \n",
    "        # Convert the preprocessed features back to DataFrame\n",
    "        X_preprocessed_df = pd.DataFrame(X_preprocessed.toarray(), columns=feature_names)\n",
    "        \n",
    "        print(f\"Preprocessing completed.\")\n",
    "        \n",
    "        return X_preprocessed_df, y\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a264422",
   "metadata": {},
   "source": [
    "## 3.4 Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4425718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "def split_data(X, y):\n",
    "    try:\n",
    "        print(\"Splitting the data...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"Data splitting completed.\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data splitting: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bef8b05",
   "metadata": {},
   "source": [
    "## 3.5 Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a7ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing features...\n",
      "Feature names: ['RegionID', 'SizeRank', 'RegionName_Albany, NY', 'RegionName_Amsterdam, NY', 'RegionName_Auburn, NY', 'RegionName_Batavia, NY', 'RegionName_Binghamton, NY', 'RegionName_Buffalo, NY', 'RegionName_Corning, NY', 'RegionName_Cortland, NY', 'RegionName_Elmira, NY', 'RegionName_Glens Falls, NY', 'RegionName_Gloversville, NY', 'RegionName_Hudson, NY', 'RegionName_Ithaca, NY', 'RegionName_Jamestown, NY', 'RegionName_Kingston, NY', 'RegionName_Malone, NY', 'RegionName_New York, NY', 'RegionName_Ogdensburg, NY', 'RegionName_Olean, NY', 'RegionName_Oneonta, NY', 'RegionName_Plattsburgh, NY', 'RegionName_Poughkeepsie, NY', 'RegionName_Rochester, NY', 'RegionName_Seneca Falls, NY', 'RegionName_Syracuse, NY', 'RegionName_Utica, NY', 'RegionName_Watertown, NY', 'StateName_NY']\n",
      "Number of feature names: 30\n",
      "Shape of transformed features: (9882, 30)\n",
      "Preprocessing completed.\n",
      "Splitting the data...\n",
      "Data splitting completed.\n",
      "Saving the split data...\n",
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save data\n",
    "def save_data(X_train, X_test, y_train, y_test):\n",
    "    try:\n",
    "        print(\"Saving the split data...\")\n",
    "        X_train.to_csv('X_train_combined.csv', index=False)\n",
    "        X_test.to_csv('X_test_combined.csv', index=False)\n",
    "        y_train.to_csv('y_train_combined.csv', index=False)\n",
    "        y_test.to_csv('y_test_combined.csv', index=False)\n",
    "        print(\"Data saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data saving: {e}\")\n",
    "\n",
    "# Preprocess the data\n",
    "X_preprocessed_df, y = preprocess_data(df, pipeline, target_column)\n",
    "\n",
    "# Ensure the preprocessing was successful before splitting the data\n",
    "if X_preprocessed_df is not None and y is not None:\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = split_data(X_preprocessed_df, y)\n",
    "    \n",
    "    # Ensure the data splitting was successful before saving the data\n",
    "    if X_train is not None and X_test is not None and y_train is not None and y_test is not None:\n",
    "        # Save the split data\n",
    "        save_data(X_train, X_test, y_train, y_test)\n",
    "    else:\n",
    "        print(\"Data splitting failed, skipping data saving.\")\n",
    "else:\n",
    "    print(\"Preprocessing failed, skipping data splitting and saving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda5bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
